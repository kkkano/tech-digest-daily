"""
AI æ™ºèƒ½æ€»ç»“ç”Ÿæˆå™¨
æ ¹æ®ç”¨æˆ·åå¥½ + çƒ­åº¦ç»¼åˆåˆ†æï¼Œç”Ÿæˆä¸ªæ€§åŒ–çš„æŠ€æœ¯æ—¥æŠ¥æ€»ç»“
"""

import json
from typing import Optional
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import NewsItem, SourceResult, AISummary, UserProfile, SourceType
from ai.llm_client import LLMClient
from ai.github_profile import GitHubProfileFetcher


class AISummarizer:
    """AI æ™ºèƒ½æ€»ç»“ç”Ÿæˆå™¨"""

    def __init__(self, llm_client: Optional[LLMClient] = None):
        """
        åˆå§‹åŒ–

        Args:
            llm_client: LLM å®¢æˆ·ç«¯å®ä¾‹
        """
        self.llm_client = llm_client or LLMClient()

    def generate_summary(
        self,
        results: list[SourceResult],
        user_profile: Optional[UserProfile] = None
    ) -> AISummary:
        """
        ç”Ÿæˆæ™ºèƒ½æ€»ç»“

        Args:
            results: å„æ•°æ®æºçš„ç»“æœåˆ—è¡¨
            user_profile: ç”¨æˆ·åå¥½æ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            AISummary å¯¹è±¡
        """
        # æ„å»º prompt
        prompt = self._build_prompt(results, user_profile)

        # è°ƒç”¨ LLM
        try:
            response = self.llm_client.chat_json(prompt, temperature=0.7)
            return AISummary.from_dict(response)
        except Exception as e:
            print(f"AI æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ€»ç»“
            return AISummary(
                summary="ä»Šæ—¥æŠ€æœ¯èµ„è®¯å·²ä¸ºæ‚¨æ•´ç†å®Œæ¯•ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹è¯¦ç»†å†…å®¹ã€‚",
                recommendations=[]
            )

    def _build_prompt(
        self,
        results: list[SourceResult],
        user_profile: Optional[UserProfile] = None
    ) -> str:
        """æ„å»º LLM Prompt - å¹³è¡¡ä¸ªæ€§åŒ–ä¸çƒ­åº¦"""

        # ç”¨æˆ·åå¥½éƒ¨åˆ†
        user_section = ""
        if user_profile:
            interests = user_profile.get_interests_summary()
            user_section = f"""
## ç”¨æˆ·èƒŒæ™¯å‚è€ƒï¼ˆä»…ä½œå‚è€ƒï¼Œä¸è¦å®Œå…¨ä¾èµ–ï¼‰

- **GitHub ç”¨æˆ·å**: {user_profile.username}
- **å¸¸ç”¨ç¼–ç¨‹è¯­è¨€**: {', '.join(interests['top_languages'][:5]) or 'æœªçŸ¥'}
- **æ„Ÿå…´è¶£çš„æŠ€æœ¯é¢†åŸŸ**: {', '.join(interests['top_topics'][:10]) or 'æœªçŸ¥'}
- **Star è¿‡çš„ä»“åº“æ•°**: {interests['starred_count']}

### æœ€è¿‘ Star çš„ä»“åº“ï¼ˆä»£è¡¨å…´è¶£æ–¹å‘ï¼‰:
{self._format_starred_repos(user_profile.starred_repos[:8])}

âš ï¸ **é‡è¦æç¤º**: ç”¨æˆ·èƒŒæ™¯ä»…ä½œä¸ºå‚è€ƒä¹‹ä¸€ã€‚å¦‚æœæœ‰éå¸¸ç«çˆ†æˆ–å…·æœ‰é‡å¤§å½±å“åŠ›çš„é¡¹ç›®/æ–‡ç« ï¼Œå³ä½¿ä¸ç”¨æˆ·èƒŒæ™¯æ— å…³ï¼Œä¹Ÿåº”è¯¥æ¨èï¼
"""

        # èµ„è®¯å†…å®¹éƒ¨åˆ† - åŒ…å«çƒ­åº¦ä¿¡æ¯
        content_sections = []
        for result in results:
            if result.success and result.items:
                section = self._format_source_items_with_score(result)
                content_sections.append(section)

        content_section = "\n\n".join(content_sections)

        # è®¡ç®—çƒ­åº¦é˜ˆå€¼
        hot_threshold = self._calculate_hot_threshold(results)

        # å®Œæ•´ Prompt
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ€æœ¯èµ„è®¯ç¼–è¾‘ï¼Œæ“…é•¿åˆ†ææŠ€æœ¯è¶‹åŠ¿å¹¶ä¸ºè¯»è€…æä¾›æœ‰ä»·å€¼çš„æ¨èã€‚

{user_section}

## ä»Šæ—¥èµ„è®¯å†…å®¹

{content_section}

---

## ä½ çš„ä»»åŠ¡

### 1. ä»Šæ—¥æŠ€æœ¯åœˆæ€»ç»“ï¼ˆ150-250å­—ï¼‰

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„ä¸­æ–‡æ€»ç»“ä»Šæ—¥æŠ€æœ¯åœˆçš„ä¸»è¦è¶‹åŠ¿å’Œçƒ­ç‚¹ï¼ŒåŒ…æ‹¬ï¼š
- æœ€ç«çˆ†çš„é¡¹ç›®/äº§å“ï¼ˆçƒ­åº¦æœ€é«˜çš„é‚£å‡ ä¸ªï¼‰
- æŠ€æœ¯åœˆçš„é‡è¦åŠ¨æ€å’Œè¶‹åŠ¿
- å€¼å¾—å…³æ³¨çš„æ–°å…´æŠ€æœ¯æˆ–å·¥å…·

**å†™ä½œé£æ ¼**: åƒä¸€ä½æ‡‚æŠ€æœ¯çš„æœ‹å‹åœ¨å’Œä½ èŠå¤©ï¼Œæ—¢ä¸“ä¸šåˆæœ‰è¶£ï¼Œå¯ä»¥é€‚å½“åŠ å…¥ä¸€äº›è§‚ç‚¹ã€‚

### 2. ç²¾é€‰æ¨è TOP 5

**æ¨èæ ‡å‡†ï¼ˆé‡è¦ï¼æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰**:

1. **ğŸ”¥ è¶…é«˜çƒ­åº¦**ï¼ˆçƒ­åº¦åˆ†æ•° > {hot_threshold}ï¼‰: æ— è®ºæ˜¯å¦åŒ¹é…ç”¨æˆ·èƒŒæ™¯ï¼Œè¿™ç§ç°è±¡çº§å†…å®¹å¿…é¡»æ¨è
2. **ğŸ“ˆ æ˜¾è‘—å¢é•¿**: ä»Šæ—¥æ–°å¢ stars/votes ç‰¹åˆ«å¤šçš„é¡¹ç›®
3. **ğŸ¯ ç”¨æˆ·åŒ¹é…**: ä¸ç”¨æˆ·æŠ€æœ¯æ ˆæˆ–å…´è¶£ç›¸å…³çš„é«˜è´¨é‡å†…å®¹
4. **ğŸ’¡ è¡Œä¸šå½±å“**: å¯èƒ½æ”¹å˜è¡Œä¸šæˆ–å·¥ä½œæ–¹å¼çš„é‡è¦é¡¹ç›®/æ–‡ç« 
5. **ğŸ†• åˆ›æ–°çªç ´**: è§£å†³é‡è¦é—®é¢˜æˆ–å¸¦æ¥æ–°æ–¹æ³•çš„å†…å®¹

**åˆ†é…å»ºè®®**:
- è‡³å°‘ 1-2 ä¸ª"å¿…çœ‹"çº§åˆ«çš„çƒ­é—¨å†…å®¹ï¼ˆå³ä½¿ä¸ç”¨æˆ·èƒŒæ™¯æ— å…³ï¼‰
- 2-3 ä¸ªä¸ç”¨æˆ·èƒŒæ™¯ç›¸å…³çš„ä¸ªæ€§åŒ–æ¨è
- è‡³å°‘ 1 ä¸ªå¯èƒ½å¼€é˜”è§†é‡çš„è·¨é¢†åŸŸæ¨è

æ¯ä¸ªæ¨èéœ€åŒ…å«ï¼š
- **title**: é¡¹ç›®/æ–‡ç« åç§°
- **source**: æ¥æºå¹³å°ï¼ˆGitHub / Hacker News / Product Hunt / Dev.toï¼‰
- **url**: åŸå§‹ URL
- **reason**: æ¨èç†ç”±ï¼ˆè¯´æ˜ä¸ºä»€ä¹ˆå€¼å¾—å…³æ³¨ï¼Œå¦‚æœæ˜¯çƒ­é—¨å†…å®¹è¦å¼ºè°ƒå…¶ç«çˆ†ç¨‹åº¦ï¼‰
- **highlight**: ç‰¹æ®Šæ ‡ç­¾ï¼ˆå¯é€‰ï¼Œå¦‚ "ğŸ”¥ çˆ†æ¬¾"ã€"ğŸ“ˆ é£™å‡"ã€"ğŸ’ å®è—"ã€"ğŸš€ å¿…çœ‹"ã€"ğŸ¯ ä¸ºä½ æ¨è" ç­‰ï¼‰

### è¾“å‡ºæ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–æ–‡å­—ï¼š

```json
{{
  "summary": "ä»Šæ—¥æŠ€æœ¯åœˆæ€»ç»“å†…å®¹...",
  "recommendations": [
    {{
      "title": "é¡¹ç›®/æ–‡ç« æ ‡é¢˜",
      "source": "æ¥æºå¹³å°",
      "url": "é“¾æ¥åœ°å€",
      "reason": "æ¨èç†ç”±",
      "highlight": "ç‰¹æ®Šæ ‡ç­¾ï¼ˆå¯é€‰ï¼‰"
    }},
    ...
  ]
}}
```
"""
        return prompt

    def _calculate_hot_threshold(self, results: list[SourceResult]) -> int:
        """è®¡ç®—çƒ­åº¦é˜ˆå€¼ï¼ˆç”¨äºè¯†åˆ«è¶…é«˜çƒ­åº¦å†…å®¹ï¼‰"""
        all_scores = []
        for result in results:
            if result.success:
                for item in result.items:
                    if item.score:
                        all_scores.append(item.score)

        if not all_scores:
            return 1000

        # ä½¿ç”¨ 75 åˆ†ä½æ•°ä½œä¸º"çƒ­é—¨"é˜ˆå€¼
        sorted_scores = sorted(all_scores, reverse=True)
        idx = max(0, len(sorted_scores) // 4)
        return sorted_scores[idx] if idx < len(sorted_scores) else sorted_scores[0]

    def _format_starred_repos(self, repos: list[dict]) -> str:
        """æ ¼å¼åŒ– Star çš„ä»“åº“åˆ—è¡¨"""
        if not repos:
            return "æš‚æ— æ•°æ®"

        lines = []
        for repo in repos[:8]:
            name = repo.get("name", "")
            desc = repo.get("description", "")[:50] if repo.get("description") else ""
            lang = repo.get("language", "")
            lines.append(f"- {name} ({lang}): {desc}")

        return "\n".join(lines)

    def _format_source_items_with_score(self, result: SourceResult) -> str:
        """æ ¼å¼åŒ–å•ä¸ªæ•°æ®æºçš„å†…å®¹ - åŒ…å«çƒ­åº¦åˆ†æ•°"""
        source_names = {
            SourceType.GITHUB: "GitHub Trending",
            SourceType.HACKERNEWS: "Hacker News",
            SourceType.PRODUCTHUNT: "Product Hunt",
            SourceType.DEVTO: "Dev.to"
        }

        name = source_names.get(result.source, str(result.source))
        lines = [f"### {name} ({len(result.items)} æ¡)"]

        for i, item in enumerate(result.items[:15], 1):
            title = item.title
            desc = item.description_cn or item.description
            desc = desc[:120] + "..." if len(desc) > 120 else desc
            url = item.url

            # çƒ­åº¦æŒ‡æ ‡
            score_str = ""
            if item.score:
                if result.source == SourceType.GITHUB:
                    stars_today = item.extra.get("stars_today", "")
                    score_str = f"â­ {item.score}"
                    if stars_today:
                        score_str += f" (ä»Šæ—¥ +{stars_today})"
                elif result.source == SourceType.HACKERNEWS:
                    score_str = f"ğŸ”º {item.score} points"
                elif result.source == SourceType.PRODUCTHUNT:
                    score_str = f"â¬†ï¸ {item.score} votes"
                elif result.source == SourceType.DEVTO:
                    score_str = f"â¤ï¸ {item.score} reactions"

            # æ·±åº¦ä¿¡æ¯
            depth_info = ""
            if item.readme_summary:
                depth_info += f"\n   ğŸ“– README: {item.readme_summary[:100]}..."
            if item.tech_stack:
                depth_info += f"\n   ğŸ› ï¸ æŠ€æœ¯æ ˆ: {', '.join(item.tech_stack[:5])}"

            lines.append(f"{i}. **{title}** {score_str}")
            lines.append(f"   {desc}")
            lines.append(f"   é“¾æ¥: {url}")
            if depth_info:
                lines.append(depth_info)

        return "\n".join(lines)


def generate_ai_summary(
    results: list[SourceResult],
    username: Optional[str] = None,
    llm_api_key: Optional[str] = None,
    github_token: Optional[str] = None
) -> AISummary:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆ AI æ™ºèƒ½æ€»ç»“

    Args:
        results: æ•°æ®æºç»“æœåˆ—è¡¨
        username: GitHub ç”¨æˆ·åï¼ˆç”¨äºä¸ªæ€§åŒ–æ¨èï¼‰
        llm_api_key: LLM API Key
        github_token: GitHub Token

    Returns:
        AISummary å¯¹è±¡
    """
    # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    llm_client = LLMClient(api_key=llm_api_key)

    # è·å–ç”¨æˆ·åå¥½
    user_profile = None
    if username:
        try:
            print(f"  ğŸ“Š æ­£åœ¨è·å– {username} çš„ GitHub åå¥½æ•°æ®...")
            fetcher = GitHubProfileFetcher(token=github_token)
            user_profile = fetcher.get_user_profile(username)
            print(f"  âœ… å·²è·å–ç”¨æˆ·åå¥½æ•°æ®")
        except Exception as e:
            print(f"  âš ï¸ è·å–ç”¨æˆ·åå¥½å¤±è´¥: {e}")

    # ç”Ÿæˆæ€»ç»“
    summarizer = AISummarizer(llm_client)
    return summarizer.generate_summary(results, user_profile)


if __name__ == "__main__":
    # æµ‹è¯•
    from sources.hackernews import HackerNewsSource

    # è·å–ä¸€äº›æµ‹è¯•æ•°æ®
    hn = HackerNewsSource()
    hn_result = hn.fetch(limit=5)

    if hn_result.success:
        print("æ­£åœ¨ç”Ÿæˆ AI æ€»ç»“...")
        summary = generate_ai_summary(
            results=[hn_result],
            username="kkkano"
        )
        print(f"\næ€»ç»“:\n{summary.summary}")
        print(f"\næ¨èæ•°: {len(summary.recommendations)}")
        for rec in summary.recommendations:
            highlight = rec.get('highlight', '')
            print(f"- {highlight} {rec.get('title')}: {rec.get('reason')}")
